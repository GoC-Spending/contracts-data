{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('stopwords')\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "# these characters are reminants of typos\n",
    "punctuation.extend([\"''\", '``'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load in files\n",
    "contracts = pd.read_csv('../data/contracts.csv', low_memory=False)\n",
    "\n",
    "categories_csv = pd.read_csv('../data/categories/gov-objs-2022.csv', dtype = str, low_memory=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop excess rows from `contacts.csv`\n",
    "contracts = contracts.drop(['vendor_postal_code', 'description_fr', 'comments_fr', 'additional_comments_fr', 'vendor_postal_code'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop excess rows from `gov-objs-2022.csv`\n",
    "categories_csv = categories_csv.drop(['Group-Groupe_code_OBJ-ART', 'Group_name-Groupe_nom_OBJ-ART', 'Category_sub-division-Sous-divisiondecatégorie_code_OBJ-ART', 'Category_sub-division_name-Sous-divisiondecatégorie_nom_OBJ-ART', 'Notes', 'Department_specific-Particulier_au_ministère'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# splitting `categories` into individual dfs with same column names so they can be concatenated\n",
    "df1 = categories_csv[['Category-Catégorie_code_OBJ-ART', 'Category_name-Catégorie_nom_OBJ-ART']].copy()\n",
    "df1.rename(columns={'Category-Catégorie_code_OBJ-ART': 'eco_obj_code',\n",
    "                    'Category_name-Catégorie_nom_OBJ-ART': 'name'}, inplace=True)\n",
    "\n",
    "df2 = categories_csv[['Sub-category-Sous-catégorie_code_OBJ-ART', 'Sub-category_name-Sous-catégorie_nom_OBJ-ART', 'Sub-category-Sous-catégorie_description_OBJ-ART']].copy()\n",
    "df2.rename(columns={'Sub-category-Sous-catégorie_code_OBJ-ART': 'eco_obj_code',\n",
    "                    'Sub-category_name-Sous-catégorie_nom_OBJ-ART': 'name',\n",
    "                    'Sub-category-Sous-catégorie_description_OBJ-ART': 'description'}, inplace=True)\n",
    "\n",
    "df3 = categories_csv[['Reportingobject-Articlederapport_code_OBJ-ART', 'Reportingobject_name-Articlederapport_nom_OBJ-ART']].copy()\n",
    "df3.rename(columns={'Reportingobject-Articlederapport_code_OBJ-ART': 'eco_obj_code',\n",
    "                    'Reportingobject_name-Articlederapport_nom_OBJ-ART': 'name'}, inplace=True)\n",
    "\n",
    "df4 = categories_csv[['Code_OBJ-ART', 'Name-Nom_OBJ-ART', 'Description_OBJ-ART']].copy()\n",
    "df4.rename(columns={'Code_OBJ-ART': 'eco_obj_code',\n",
    "                    'Name-Nom_OBJ-ART': 'name',\n",
    "                    'Description_OBJ-ART': 'description'}, inplace=True)\n",
    "\n",
    "categories = pd.concat([df1, df2, df3, df4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# getting only unique EOCs for categorisation\n",
    "categories = categories.drop_duplicates(subset=['eco_obj_code'], ignore_index=True)\n",
    "categories"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating table of EOCs which exist in `contracts.csv` for manual categorization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TEMP COPY OF CONTRACTS DF FOR EXPERIMENTING BELOW\n",
    "temp_contracts = contracts\n",
    "temp_cats = categories"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_desc(desc):\n",
    "    if type(desc) is str:\n",
    "        tokens = word_tokenize(desc.lower())\n",
    "\n",
    "        stwords = stopwords.words('english')\n",
    "        newDesc = [token for token in tokens if token not in stwords and token not in punctuation]\n",
    "        \n",
    "        return newDesc\n",
    "\n",
    "    \n",
    "\n",
    "# temp_cats['name'] = temp_cats['name'].apply(clean_desc)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for row_index, eco_code in enumerate(temp_contracts['economic_object_code']):\n",
    "    # check for rows with no EOC or incorrectly formatted EOCs\n",
    "    if pd.isna(eco_code) or eco_code[0].isdigit() == False:\n",
    "        if pd.isna(temp_contracts.loc[row_index]['description_en']) == False:\n",
    "            split_desc = clean_desc(temp_contracts.loc[row_index]['description_en'])\n",
    "            for str_index, s in enumerate(split_desc):\n",
    "                if s.isdigit():\n",
    "                    if s[0] == '0':\n",
    "                        # easy match: if number begins with 0 then it can be presumed to be an object code\n",
    "                        temp_contracts.loc[row_index, 'economic_object_code'] = s\n",
    "                    elif len(s) >= 3 and str_index == 0:\n",
    "                        # harder match: what about the 4 digit codes or the ones that don't follow the correct format?\n",
    "                        # solution: if number is >= 3 digits in length and the number is at index 0, then match number to categories \n",
    "                        # s = normalise_codes(s)\n",
    "                        temp_contracts.loc[row_index, 'economic_object_code'] = s\n",
    "                    elif str_index == 0:\n",
    "                        # case for if digit is in first position (likely to be EOC)\n",
    "                        temp_contracts.loc[row_index, 'economic_object_code'] = s\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_cats['name'] = temp_cats['name'].apply(clean_desc)\n",
    "\n",
    "# final check to match descriptions of rows with no EOC or number in description\n",
    "for row_index, eco_code in enumerate(temp_contracts['economic_object_code']):\n",
    "        split_desc = clean_desc(temp_contracts.loc[row_index]['description_en'])\n",
    "        if pd.isna(eco_code) or eco_code[0].isdigit() == False:\n",
    "            matches = []\n",
    "            for i, d in enumerate(temp_cats['name']):\n",
    "                if split_desc == d:\n",
    "                    matches.append(temp_cats.loc[i])\n",
    "            if len(matches) > 0:\n",
    "                if matches[0]['name'] != None:\n",
    "                    temp_contracts.loc[row_index, 'economic_object_code'] = matches[0]['eco_obj_code']\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "forCate = temp_contracts.drop_duplicates(subset=['economic_object_code'], ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "forSean = pd.read_csv('../data/categories/REVISED_economic_object_codes_to_category.csv', dtype = str, low_memory=False)\n",
    "\n",
    "forSean['example_description_en'] = forSean['example_description_en'].apply(clean_desc)\n",
    "\n",
    "forCate['category'] = pd.Series()\n",
    "\n",
    "for row_index, eco_code in enumerate(forCate['economic_object_code']):\n",
    "    split_desc = clean_desc(forCate.loc[row_index]['description_en'])\n",
    "    matches = []\n",
    "    for i, d in enumerate(forSean['example_description_en']):\n",
    "        if split_desc == d:\n",
    "            matches.append(forSean.loc[i])\n",
    "    if len(matches) > 0:\n",
    "        if matches[0]['example_description_en'] != None:\n",
    "            print(matches[0])\n",
    "            forCate.loc[row_index, 'category'] = matches[0]['category']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "forCate = forCate[['economic_object_code', 'description_en', 'category']].copy()\n",
    "forCate\n",
    "# forCate.to_csv('for-Sean-revision.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code for Categorisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_contracts = temp_contracts\n",
    "cat_contracts.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EOCs exported incorrectly from after Sean manual categorization\n",
    "# can be amended by row index\n",
    "classifications1 = pd.read_csv('manual_categorisation.csv', dtype = str, low_memory=False)\n",
    "\n",
    "for row_index, eco_code in enumerate(classifications1['economic_object_code']):\n",
    "    classifications1.loc[row_index, 'economic_object_code'] = forCate.loc[row_index, 'economic_object_code']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fix Excel removal of leading 0s from Sean categorization pt2\n",
    "classifications2 = pd.read_csv('../data/categories/economic_object_codes_to_category.csv', dtype = str, low_memory=False)\n",
    "\n",
    "for row_index, eco_code in enumerate(classifications2['economic_object_code']):\n",
    "    if eco_code not in list(classifications1['economic_object_code']):\n",
    "        mod_eco_code = '0' + eco_code\n",
    "        if mod_eco_code in list(classifications1['economic_object_code']):\n",
    "            classifications2.loc[row_index, 'economic_object_code'] = mod_eco_code"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fix discrepancies\n",
    "des_r = pd.read_csv('descrepancies_reconciled.csv', dtype = str, low_memory=False)\n",
    "\n",
    "for row_index, eco_code in enumerate(des_r['economic_object_code']):\n",
    "    if eco_code not in list(classifications1['economic_object_code']):\n",
    "        mod_eco_code = '0' + eco_code\n",
    "        if mod_eco_code in list(classifications1['economic_object_code']):\n",
    "            des_r.loc[row_index, 'economic_object_code'] = mod_eco_code\n",
    "\n",
    "merged_sb_class = pd.merge(classifications2, des_r, how=\"outer\", on=[\"economic_object_code\"])\n",
    "\n",
    "for row_index, cate in enumerate(merged_sb_class['category_latest']):\n",
    "    if type(cate) == str:\n",
    "        merged_sb_class.loc[row_index, \"category\"] = cate\n",
    "\n",
    "classifications2 = merged_sb_class[['economic_object_code', 'category']].copy()\n",
    "\n",
    "merged = pd.merge(classifications1, classifications2, how=\"outer\", on=[\"economic_object_code\"])\n",
    "\n",
    "for row_index, cate in enumerate(merged['category_x']):\n",
    "    if type(cate) != str:\n",
    "        if type(merged.loc[row_index, \"category_y\"]) == str:\n",
    "           merged.loc[row_index, \"category_x\"] = merged.loc[row_index, \"category_y\"]\n",
    "        \n",
    "classifications = merged.drop_duplicates(subset=['economic_object_code'])\n",
    "classifications = classifications[['economic_object_code', 'description_en', 'category_x']].copy()\n",
    "classifications = classifications.rename(columns={'category_x':'category'})\n",
    "\n",
    "# merged.loc[merged['category_x'].notna()]\n",
    "# merged = merged.loc[merged['category_cb'] != merged['category_sb']]\n",
    "# merged = merged.loc[merged['category_cb'].notna() & merged['category_sb'].notna()]\n",
    "\n",
    "# merged.to_csv('descrepancies.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifications"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create column for classification\n",
    "cat_contracts.insert(6,'category', '')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def classify(code):\n",
    "    find_class = classifications.loc[classifications['economic_object_code'] == code]\n",
    "    return find_class\n",
    "\n",
    "for row_index, eco_code in enumerate(cat_contracts['economic_object_code']):\n",
    "    if pd.isna(eco_code) == False:\n",
    "        loc_class = classify(eco_code)\n",
    "        if loc_class.empty:\n",
    "            mod_code = ''\n",
    "            if eco_code[0] == '0':\n",
    "                mod_code = eco_code[1:]\n",
    "            else:\n",
    "                mod_code = '0' + eco_code\n",
    "\n",
    "            loc_class = classify(mod_code)\n",
    "\n",
    "            if loc_class.empty == False:\n",
    "                cat_contracts.loc[row_index, 'category'] = loc_class.iloc[0]['category']\n",
    "            else:\n",
    "                cat_contracts.loc[row_index, 'category'] = np.NaN\n",
    "\n",
    "        else:\n",
    "            cat_contracts.loc[row_index, 'category'] = loc_class.iloc[0]['category']\n",
    "        \n",
    "        print(eco_code)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we will now export the contracts data as is and attempt to create a text classifier for the remaining 204416 rows without any EOC or description match \n",
    "cat_contracts.to_csv('rule_based_contracts_v1.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PREVIOUS RULE-BASED CLASSIFIER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find word frequency for each category to classify rows with no EOC later\n",
    "unique_classifiers = [c for c in cat_contracts['category'].unique() if str(c) != 'nan' and len(str(c)) > 1]\n",
    "\n",
    "unique_classifiers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cate_keywords = {}\n",
    "for c in unique_classifiers:\n",
    "    class_df = cat_contracts.loc[cat_contracts['category'] == c]\n",
    "\n",
    "    class_ls = class_df['description_en'].tolist()\n",
    "\n",
    "    class_str = ' '.join(str(w) for w in class_ls).lower()\n",
    "    class_str = clean_desc(class_str)\n",
    "    class_str = [t for t in class_str if t.isalpha()]\n",
    "\n",
    "    dist = FreqDist(class_str)\n",
    "\n",
    "    word_freq = [ws[0] for ws in dist.most_common(15)]\n",
    "    \n",
    "    cate_keywords[c] = word_freq\n",
    "    print(c)\n",
    "    print(cate_keywords[c])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# identify duplicates in keyword lists so they can be removed\n",
    "\n",
    "# using sets to ensure no duplicates\n",
    "distinct = set()\n",
    "duplicate = set()\n",
    "\n",
    "for k, v in cate_keywords.items():\n",
    "  for i in set(v):\n",
    "    if i in distinct:\n",
    "      duplicate.add(i)\n",
    "    else:\n",
    "      distinct.add(i)\n",
    "\n",
    "print(distinct)\n",
    "print(duplicate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TO DO\n",
    "# adding vague words like \"fees\" and \"misc\" to words that should be removed to avoid confusion\n",
    "# tbh maybe topic model or text classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# remove duplicates from keyword lists\n",
    "for k, v in cate_keywords.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    intersection = set(v) - duplicate\n",
    "    print(intersection)\n",
    "    print('------------------')\n",
    "    cate_keywords[k] = list(intersection)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cate_keywords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = 0\n",
    "match_list = []\n",
    "for row_index, cate in enumerate(cat_contracts['category']):\n",
    "    # checking len of category name bc dynamic typing is great but also sucks\n",
    "    if len(str(cate)) <= 3:\n",
    "        tokenize_desc = clean_desc(cat_contracts.loc[row_index, 'description_en'])\n",
    "        if tokenize_desc is not None:\n",
    "            for k, v in cate_keywords.items():\n",
    "                print(k)\n",
    "                intersection = set(tokenize_desc).intersection(v)\n",
    "                print(intersection)\n",
    "                if len(intersection) > 0:\n",
    "                    match_list.append(k)\n",
    "            if len(match_list) > 1:\n",
    "                print(tokenize_desc)\n",
    "                print('MATCH: ' + str(match_list))\n",
    "    print('--------------------')\n",
    "    match_list = []\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('vs_code_server': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "interpreter": {
   "hash": "af0adeb7edf4a3c4c0485090f935cd1c251e95d3c0c8aed98fcb71051a2996d7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}